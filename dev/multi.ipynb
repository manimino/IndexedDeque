{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8f13c30",
   "metadata": {},
   "source": [
    "#### Multi-attribute indexing\n",
    "\n",
    "The one place SQLite will still have a speed edge is in multidimensional range queries using a multi-attribute index. For equality, no prob - concatenate the values into a tuple and you're good to go. That beats SQLite by a lot, and works on both index types. But `a < 5 and b < 6`, not so much.\n",
    "\n",
    "Here, let's demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7a50a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "from litebox import LiteBox\n",
    "from filterbox import FilterBox, FrozenFilterBox\n",
    "\n",
    "objs = [{'a': random.random(), 'b': random.random()} for _ in range(10**6)]\n",
    "lb = LiteBox(objs, {'a': float, 'b': float})\n",
    "lb_multi = LiteBox(objs, {'a': float, 'b': float}, index=[('a', 'b')])\n",
    "fb = FilterBox(objs, ['a', 'b'])\n",
    "ffb = FrozenFilterBox(objs, ['a', 'b'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "496467f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528 µs ± 10.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "lb.find(\"a < 0.001 and b < 0.001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13264dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677 µs ± 12.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "fb[{'a': {'<': 0.001}, 'b': {'<': 0.001}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9533ee92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.1 µs ± 780 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "ffb[{'a': {'<': 0.001}, 'b': {'<': 0.001}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cd618f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now the multi-attribute indexing, blam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b7529fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.7 µs ± 322 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "lb_multi.find(\"a < 0.001 and b < 0.001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3ba56c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204 µs ± 3.33 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# not gonna beat it with something naive either\n",
    "[o for o in ffb[{'a': {'<': 0.001}}] if o['b'] < 0.001]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfe9510",
   "metadata": {},
   "source": [
    "Unfortunately, there's not really a good way to implement a multi-attr index here. \n",
    "BTree doesn't support multi-attribute lookups afaik.\n",
    "\n",
    "So we're kinda stuck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab0ec6e",
   "metadata": {},
   "source": [
    "Contrary to popular belief, you can't just \"concatenate the keys and use a regular BTree\". At least, not with this implementation; it doesn't support separate lookups for \"parts\" of a key, so you'd be treating the whole key as one object. \n",
    "\n",
    "But! We can make a BTree of `{obj: obj}`, so `BTree{key1: BTree{key2: values}}` could work. Except that when `key1`'s values are all unique... you get a whole ton of BTrees.\n",
    "\n",
    "OK, so we still don't have a good idea. Making a multi-attribute BTree out of a single-attribute one doesn't seem doable.\n",
    "\n",
    "The best hack I can think of is:\n",
    " - Build the tree on concatenated keys `{(key1, key2): values}` \n",
    " - Get {keys: values} in the range `(k1_min, -inf) < (k1, k2) < (k1_max, inf)`. \n",
    " - Post-filter keys that don't match the k2 constraint.\n",
    " - Return only the values with matching keys.\n",
    "\n",
    "The order bound isn't living up to tree standards, but I bet it would be passable most of the time anyway. Probably beats doing a separate search on key2 and intersecting the results.\n",
    "\n",
    "The `-inf / inf` values would need to be some type-independent thing. `None` is always small in BTrees so that could be the lower bound.\n",
    "\n",
    "Could cram it in at the value level instead? `BTree({key1: [(key2, val), (key2, val) ...]` Avoids the awkward comparisons. Burns some RAM though. And it's really equivalent to just using one index and doing the rest in a list comprehension outside the container. \n",
    "\n",
    "### todo\n",
    "think about the frozen arrays and how you would implement it there. That might give good insights.\n",
    "Sparse ndarrays maybe? Quad / octrees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f91c00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from filterbox.btree import BTree\n",
    "from random import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b796fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "objs = [\n",
    "    {'i': i, 'a': random()*10, 'b': random()} for i in range(10**3)\n",
    "]\n",
    "\n",
    "# Task: Find objs where 1 < a < 2 and 0.5 < b < 0.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad908e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = BTree()\n",
    "for o in objs:\n",
    "    tree[o['a']] = (o['b'], o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6274a4a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 191, 'a': 1.0570674936431124, 'b': 0.5649662294471903}\n",
      "{'i': 437, 'a': 1.3542792185455155, 'b': 0.5753256982901156}\n",
      "{'i': 185, 'a': 1.401839984653963, 'b': 0.5310477476841865}\n",
      "{'i': 772, 'a': 1.44039489179562, 'b': 0.5176671572926902}\n",
      "{'i': 457, 'a': 1.469287583082859, 'b': 0.5475469700864543}\n",
      "{'i': 943, 'a': 1.5722080241319658, 'b': 0.5615369447345585}\n",
      "{'i': 231, 'a': 1.6165395202332788, 'b': 0.5551452004632332}\n",
      "{'i': 92, 'a': 1.7698873658963565, 'b': 0.5834212111319615}\n",
      "{'i': 392, 'a': 1.834056255838259, 'b': 0.545838844154715}\n",
      "{'i': 691, 'a': 1.8549647165079397, 'b': 0.5517766855664482}\n"
     ]
    }
   ],
   "source": [
    "for b, o in tree.get_range_expr({'>': 1, '<': 2}):\n",
    "    if b < 0.6 and b > 0.5:\n",
    "        print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "634cfaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributes are hashable, so this could work as a dict too. But that's less general.\n",
    "# Or parallel arrays, one for each attribute, plus one for the object ID. Nah, too hard to add/remove items.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c03ff5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
