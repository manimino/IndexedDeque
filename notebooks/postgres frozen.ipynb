{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2477482",
   "metadata": {},
   "source": [
    "#### keep obj refs in buckets\n",
    "\n",
    "There's an optimization possible with the postgres stuff\n",
    "- if the bucket owns its objects, e.g. in list form\n",
    "- and we want the entire bucket (because it only has 1 key, and we want that key)\n",
    "- we could just grab all the objects and return them in one shot\n",
    "\n",
    "downside: if we have an arbitrary obj id, which bucket did it come from? we dunno\n",
    "need to drag obj refs along with the obj ids up to higher levels then\n",
    "\n",
    "so when I query a bucket, the return value looks like:\n",
    "\n",
    "```\n",
    "[\n",
    "  obj_ids: sorted np array\n",
    "  objs: list\n",
    "  all_true: bool, True if there's no mask needed because we still want every obj \n",
    "  mask: bool np array or None. \n",
    "]\n",
    "```\n",
    "\n",
    "Then we maintain a whole lot of those structures as we go up. Like we'll have a list of 'em that we wanna union() at the end of `match`, and another list for everything we wanna `exclude`. \n",
    "\n",
    "Problem: duplicated storage\n",
    " - We are now storing many obj references in each idx instead of just once overall. \n",
    " - RAM cost per index is higher by 8 bytes / index / item. \n",
    "\n",
    "#### Full match\n",
    "\n",
    "To handle a query like:\n",
    "\n",
    "`find(match={}, exclude={'something': 'small'})`\n",
    "\n",
    "we'll need to do a scan across one of the indices to get all items first. \n",
    "\n",
    "Optionally, we could preserve a dummy index that contains all items in one key, just for the \"I need everything\" query (e.g. when doing an `__iter__`.\n",
    "\n",
    "\n",
    "#### multiple matches / excludes\n",
    "\n",
    "Currently some queries are not expressible. Find me everything with `a=1 and [(b != 2) or (c != 3)]`. \n",
    "\n",
    "We could get one level deeper by accepting lists, like `match={a:1}, exclude=[{b: 2}, {c: 3}]`. Accepting list-of-list and so on could keep going deeper still. It makes a tree, which we can eval from the ground up.\n",
    "\n",
    "Not sure whether we wanna go down that road. Sounds long. \n",
    "\n",
    "Just something to keep in mind as we update the ol' query evaluation engine to fit this new approach.\n",
    "\n",
    "ON SECOND THOUGHT. We can index general functions. A user could just make an index on:\n",
    "\n",
    "```\n",
    "def not_these(obj):\n",
    "    return b != 2 or c != 3\n",
    "```\n",
    "\n",
    "And then\n",
    "```\n",
    "hi = HashIndex(items, on=['a', not_these]\n",
    "hi.find({'a': 1, not_these: True)\n",
    "```\n",
    "\n",
    "which would be more efficient anyway. So screw complexity. Yay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7b424ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from bisect import bisect_left\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "from sortedcontainers import SortedDict\n",
    "from pympler.asizeof import asizeof\n",
    "import sortednp as snp\n",
    "from operator import itemgetter\n",
    "from typing import List, Optional, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fb0d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2474fd46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aa611043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SomeObjs:\n",
    "    # todo: slots=true\n",
    "    obj_ids: np.ndarray = np.array(dtype='uint64') # sorted np array of ints\n",
    "    objs: List[Any] # sorted by obj_id\n",
    "    has_nan_ids: bool = False # Some obj_ids will be set to np.NaN during intersect operations\n",
    "\n",
    "        \n",
    "def remove_nan_ids(s: SomeObjs):\n",
    "    # mutates s\n",
    "    if s.all_true:\n",
    "        return\n",
    "    s.obj_ids = s.obj_ids[s.mask]\n",
    "    # itemgetter is faster than a generator expression for subselecting a list by indices\n",
    "    # just needs extra handling \n",
    "    pos = np.where(s.mask)[0]\n",
    "    if len(pos) == 0:\n",
    "        s.objs = []\n",
    "    elif len(pos) == 1:\n",
    "        s.objs = [s.objs[pos[0]]]\n",
    "    else:\n",
    "        s.objs = list(itemgetter(*pos)(s.objs))\n",
    "    s.all_true = True\n",
    "    s.mask = None  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "befc4452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itemgetter 0.028338909149169922\n",
      "list comp 0.0499112606048584\n"
     ]
    }
   ],
   "source": [
    "# proof that itemgetter is faster, even with the cast to list\n",
    "pos = list(range(10**6))\n",
    "objs = list(range(10**6))\n",
    "t0 = time.time()\n",
    "q = list(itemgetter(*pos)(objs))\n",
    "t1 = time.time()\n",
    "r = [objs[i] for i in pos]\n",
    "t2 = time.time()\n",
    "print('itemgetter', t1-t0)\n",
    "print('list comp', t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4dd5f229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_remove_nan_ids():\n",
    "    # mask bits typically get set after an intersect / difference operation\n",
    "    s = SomeObjs(obj_ids = np.array([1,2,3], dtype='uint64'), objs=['a', 'b', 'c'], all_true=True, mask=None)\n",
    "\n",
    "    s.all_true = False\n",
    "    # todo parameterize for 0, 1, 2, and 3 trues -- all different outcomes\n",
    "    s.mask = np.array([True, False, True], dtype=bool)\n",
    "\n",
    "    apply_mask(s)\n",
    "    assert s.objs == ['a', 'c']\n",
    "    \n",
    "test_apply_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecec9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_id(s: SomeObjs):\n",
    "    # mutates s\n",
    "    sort_order = s.obj_ids.argsort()\n",
    "    s.obj_ids = s.obj_ids[sort_order]\n",
    "    s.objs = s.objs[sort_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a5bd2ca8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3620735981.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_111334/3620735981.py\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    isect = snp.[1]\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def union_all(ls: List[SomeObjs]) -> SomeObjs:\n",
    "    # so we take the union'd IDs\n",
    "    # then we intersect them with each SomeObjs one at a time\n",
    "    # on intersect, we:\n",
    "    # - grab the obj and its id, add it to the output SomeObjs\n",
    "    # - nan out the copy of it in the unionset\n",
    "    # Last step, sort. We'll need a function for that.\n",
    "    result = SomeObjs()\n",
    "    union_ids = snp.kway_merge(*[s.obj_ids for s in ls], assume_sorted=True, duplicates=snp.DROP)\n",
    "    for s in ls:\n",
    "        isect_idxs = snp.[1]\n",
    "    \n",
    "    print(ids)\n",
    "\n",
    "s = SomeObjs(obj_ids = np.array([1,2,3], dtype='uint64'), objs=['a', 'b', 'c'], all_true=True, mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c85cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea: use nans instead of a mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5516cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def intersect_all(ls: List[SomeObjs]):\n",
    "    pass\n",
    "\n",
    "def difference(objs: SomeObjs, not_these: SomeObjs):\n",
    "    pass\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
