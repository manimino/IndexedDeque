{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88fd1d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple, Union, Callable, Any, Iterable\n",
    "from hashindex.utils import get_field\n",
    "import random\n",
    "from cykhash import Int64Set\n",
    "\n",
    "def get_field(obj, field):\n",
    "    if callable(field):\n",
    "        val = field(obj)\n",
    "    elif isinstance(obj, dict):\n",
    "        val = obj.get(field, None)\n",
    "    else:\n",
    "        val = getattr(obj, field, None)\n",
    "    return val\n",
    "\n",
    "\n",
    "SIZE_THRESH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aceb1940",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sort_by_hash(\n",
    "    objs: Iterable[Any], field: Union[Callable, str]\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Sort objs and vals by vals.\n",
    "\n",
    "    Takes 450ms for 1M objs on a numeric field. May take longer if field is a Callable or is hard to hash.\n",
    "    Breakdown:\n",
    "     - 100ms to do all the get_field() calls. Cost is the part that inspects each obj to see if it's a dict.\n",
    "     - 220ms to get and hash the field for each obj. No getting around that.\n",
    "     - 100ms to sort the hashes\n",
    "     - 30ms of whatever\n",
    "    \"\"\"\n",
    "    hash_arr = np.empty(len(objs), dtype='int64')\n",
    "    val_arr = np.empty(len(objs), dtype='O')\n",
    "    obj_arr = np.array(objs, dtype='O')\n",
    "    for i, o in enumerate(objs):\n",
    "        val_arr[i] = get_field(o, field)\n",
    "        hash_arr[i] = hash(val_arr[i])\n",
    "        objs[i] = get_field(o, field)\n",
    "    sort_order = np.argsort(hash_arr)\n",
    "    val_arr = val_arr[sort_order]\n",
    "    obj_arr = obj_arr[sort_order]\n",
    "    return hash_arr, val_arr, obj_arr\n",
    "\n",
    "\n",
    "def group_by_val(hash_arr: np.ndarray, val_arr: np.ndarray, obj_arr: np.ndarray):\n",
    "    \"\"\"Modifies val_arr and obj_arr so that they group elements having the same value.\n",
    "\n",
    "    Does not modify hash_arr, as we won't need it past this point.\n",
    "\n",
    "    \"\"\"\n",
    "    def _group_by_val_same_hash(val_arr, obj_arr, p0, p1):\n",
    "        \"\"\"Does group_by for a subarray all having the same hash but containing >=2 distinct values.\n",
    "\n",
    "        Normal tools for doing group_by fail here.\n",
    "        - We can't assume values are sortable, so can't just sort the values and find change points.\n",
    "        - We are grouping values that have the same hash, so dict() will be inefficient.\n",
    "\n",
    "        So just making a list for each distinct value and appending the indices to it will work.\n",
    "        That will be O(n*k), where k = num of distinct values.\n",
    "        Luckily, we don't expect too many distinct values with the same hash.\n",
    "        Having more than two hashes colliding probably means the user is doing something funky, and bad\n",
    "        performance is ok in that case.\n",
    "        \"\"\"\n",
    "        distinct_vals = []\n",
    "        val_idx_lists = []  # list of list of indices. All elements in the inner list have the same val.\n",
    "        for i in range(p0, p1):\n",
    "            try:\n",
    "                idx = distinct_vals.index(val_arr[i])\n",
    "                val_idx_lists[idx].append(i)\n",
    "            except ValueError:\n",
    "                distinct_vals.append(val_arr[i])\n",
    "                val_idx_lists.append([i])\n",
    "\n",
    "        # concat the val_idx_lists to make one array of indices, like how argsort output looks\n",
    "        sort_idxs = []\n",
    "        for ixl in val_idx_lists:\n",
    "            sort_idxs.extend(ixl)\n",
    "\n",
    "        # now apply that to each array inplace\n",
    "        val_arr[p0:p1] = val_arr[sort_idxs]\n",
    "        obj_arr[p0:p1] = obj_arr[sort_idxs]\n",
    "\n",
    "    mismatch_hash = hash_arr[1:] != hash_arr[:-1]\n",
    "    hash_change_pts = np.append(np.where(mismatch_hash), len(hash_arr) - 1)\n",
    "    p0 = 0\n",
    "    for end_i in hash_change_pts:\n",
    "        p1 = end_i + 1\n",
    "        if p1-p0 > 1:\n",
    "            v = val_arr[p0]\n",
    "            non_v_values = np.where(val_arr[p0+1:p1] != v)\n",
    "            if len(non_v_values):  # False unless there's a hash collision\n",
    "                _group_by_val_same_hash(val_arr, obj_arr, p0, p1)\n",
    "        p0 = p1\n",
    "\n",
    "\n",
    "def run_length_encode(val_arr: np.ndarray):\n",
    "    \"\"\"\n",
    "    Find counts of each val in the val_arr (sorted) via run-length encoding.\n",
    "\n",
    "    Takes 10ms for 1M objs.\n",
    "    \"\"\"\n",
    "    mismatch_val = val_arr[1:] != val_arr[:-1]\n",
    "    change_pts = np.append(np.where(mismatch_val), len(val_arr) - 1)\n",
    "    counts = np.diff(np.append(-1, change_pts))\n",
    "    starts = np.cumsum(np.append(0, counts))[:-1]\n",
    "    return starts, counts, val_arr[change_pts]\n",
    "\n",
    "\n",
    "def compute_mutable_dict(objs, field):\n",
    "    \"\"\"Create a dict of {val: obj_ids}. Used when creating a mutable index.\"\"\"\n",
    "    sorted_hashes, sorted_vals, sorted_objs = hash_and_sort(objs, field)\n",
    "    group_by_val(sorted_hashes, sorted_vals, sorted_objs)\n",
    "    starts, counts, unique_vals = run_length_encode(sorted_vals)\n",
    "    d = dict()\n",
    "    for i, v in enumerate(unique_vals):\n",
    "        start = starts[i]\n",
    "        count = counts[i]\n",
    "        if counts[i] > SIZE_THRESH:\n",
    "            d[v] = Int64Set(id(obj) for obj in sorted_objs[start:start+count])\n",
    "        else:\n",
    "            d[v] = tuple(id(obj) for obj in sorted_objs[start:start+count])\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "876ab024",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Collider:\n",
    "\n",
    "    VALS = list(range(10))\n",
    "\n",
    "    def __init__(self):\n",
    "        self.n = random.choice(self.VALS)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self.n % 2\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.n == other.n\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffea8636",
   "metadata": {},
   "outputs": [],
   "source": [
    "objs = [Collider() for _ in range(20)]\n",
    "# objs = [{'n': i%2} for i in range(10)]\n",
    "field = 'n'\n",
    "\n",
    "sorted_hashes, sorted_vals, sorted_objs = sort_by_hash(objs, field)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e70a7d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 7, 7, 7, 8, 9, 9, 9],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f564515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 7, 7, 7, 8, 9, 9, 9],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_by_val(sorted_hashes, sorted_vals, sorted_objs)\n",
    "sorted_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e4f3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
